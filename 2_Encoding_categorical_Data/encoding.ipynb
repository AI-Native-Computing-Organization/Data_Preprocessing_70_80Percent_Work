{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5961faf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\shahr\\anaconda3\\envs\\ml_0_hero\\lib\\site-packages (2.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "052e5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b218fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A']\n",
      " ['B']\n",
      " ['C']\n",
      " ['D']]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a=[\"A\"],['B'],['C'],['D']\n",
    "X=np.array(a)\n",
    "print(X)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "204041c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A']\n",
      " ['B']\n",
      " ['C']\n",
      " ['D']]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X=np.array([[\"A\"],['B'],['C'],['D']])\n",
    "print(X)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e22ce",
   "metadata": {},
   "source": [
    "# Transforming categorical data (A,B, C, D) into binary values (000,001,010,011,111)\n",
    "\n",
    "One-Hot Encoding (OHE)\n",
    "One-hot encoding converts categorical values into binary columns (0s and 1s).\n",
    "By default, it creates one column per category, but this can lead to redundancy (the \"dummy variable trap\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff312029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe=OneHotEncoder() #it's a sparse matrix\n",
    "\n",
    "\n",
    "ohe.fit_transform(X).todense()  #Explicitly converts sparse matrix to dense\n",
    "\n",
    "# A is now represented as 1 0 0 0 \n",
    "# B is represented as 0 1 0 0 \n",
    "# C as 0 0 1 0\n",
    "# D as 0 0 0 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2cdc7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ohe_1=OneHotEncoder(sparse_output=False)#without sparse matrix\n",
    "ohe_1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d653b25",
   "metadata": {},
   "source": [
    "# Removing one variable/column (Standard OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fb9a87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy Use drop=\"first\"?\\n- Avoids Multicollinearity: Critical for linear models (e.g., regression) where correlated features distort coefficients.\\n\\n- Reduces Dimensionality: For k categories, you get k-1 columns instead of k.\\n\\nExample: If you have 100 categories, you save 1 column (useful for high-cardinality data).\\n\\n- Interpretability: In regression, coefficients are relative to the dropped category (baseline).'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([[\"A\"],['A'],['C'],['D']])\n",
    "#print(X)\n",
    "#print(type(X))\n",
    "\n",
    "ohe_1=OneHotEncoder(sparse_output=False,drop=\"first\")#without sparse matrix\n",
    "ohe_1.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "[[0., 0.],  # A (baseline)\n",
    " [0., 0.],  # A\n",
    " [1., 0.],  # C (means \"C=1, D=0\")\n",
    " [0., 1.]]  # D (means \"C=0, D=1\")'''\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Columns: C=1,0, D=0,1\n",
    "\n",
    "\"A\" is dropped: It becomes the reference category (all zeros).\n",
    "\n",
    "Now, the encoded features are not multicollinear.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Why Use drop=\"first\"?\n",
    "- Avoids Multicollinearity: Critical for linear models (e.g., regression) where correlated features distort coefficients.\n",
    "\n",
    "- Reduces Dimensionality: For k categories, you get k-1 columns instead of k.\n",
    "\n",
    "Example: If you have 100 categories, you save 1 column (useful for high-cardinality data).\n",
    "\n",
    "- Interpretability: In regression, coefficients are relative to the dropped category (baseline).'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f12729",
   "metadata": {},
   "source": [
    "# Used in Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e58ff88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis cretes 2 labels one with 0 and another with 1. If we don't use drop, it would assign A as 1 0 and D as 0 1.\\n\\nSo,\\n[[1 0],\\n[1 0],\\n[1 0],\\n[0 1]]\\n\\nBut if used drop , we get this. So,  it's simple now.\\narray([[0.],\\n       [0.],\\n       [0.],\\n       [1.]])\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([[\"A\"],['A'],['A'],['D']]) # we have 2 labels now\n",
    "#print(X)\n",
    "#print(type(X))\n",
    "\n",
    "ohe_1=OneHotEncoder(sparse_output=False,drop=\"first\")#without sparse matrix\n",
    "ohe_1.fit_transform(X)\n",
    "\n",
    "\"\"\"\n",
    "This cretes 2 labels one with 0 and another with 1. If we don't use drop, it would assign A as 1 0 and D as 0 1.\n",
    "\n",
    "So,\n",
    "[[1 0],\n",
    "[1 0],\n",
    "[1 0],\n",
    "[0 1]]\n",
    "\n",
    "But if used drop , we get this. So,  it's simple now.\n",
    "array([[0.],\n",
    "       [0.],\n",
    "       [0.],\n",
    "       [1.]])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b1242",
   "metadata": {},
   "source": [
    "# Error Handling for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b0d65c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assume we have 2 labels\n",
    "X=np.array([[\"A\"],['A'],['A'],['B']]) # we have 2 labels now\n",
    "#print(X)\n",
    "#print(type(X))\n",
    "\n",
    "ohe_1=OneHotEncoder(sparse_output=False) #trained on 2 labels\n",
    "ohe_1.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81436199",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [np.str_('C')] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m Y=np.array([[\u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m],[\u001b[33m'\u001b[39m\u001b[33mA\u001b[39m\u001b[33m'\u001b[39m],[\u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m],[\u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m]]) \u001b[38;5;66;03m#here we have A, C, B label\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# as ohe_1 was trained on 2 labels, it can't process 3 labels now\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mohe_1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Found unknown categories [np.str_('C')] in column 0 during transform\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shahr\\anaconda3\\envs\\ML_0_Hero\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shahr\\anaconda3\\envs\\ML_0_Hero\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1043\u001b[39m, in \u001b[36mOneHotEncoder.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1038\u001b[39m     warn_on_unknown = \u001b[38;5;28mself\u001b[39m.drop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[32m   1039\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1040\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minfrequent_if_exist\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1041\u001b[39m     }\n\u001b[32m   1042\u001b[39m     handle_unknown = \u001b[38;5;28mself\u001b[39m.handle_unknown\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m X_int, X_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m n_samples, n_features = X_int.shape\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\shahr\\anaconda3\\envs\\ML_0_Hero\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:218\u001b[39m, in \u001b[36m_BaseEncoder._transform\u001b[39m\u001b[34m(self, X, handle_unknown, ensure_all_finite, warn_on_unknown, ignore_category_indices)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown == \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    214\u001b[39m     msg = (\n\u001b[32m    215\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m during transform\u001b[39m\u001b[33m\"\u001b[39m.format(diff, i)\n\u001b[32m    217\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[31mValueError\u001b[39m: Found unknown categories [np.str_('C')] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "# if we now present a data which has different labels than A & B, it will give error\n",
    "\n",
    "Y=np.array([[\"A\"],['A'],['B'],['C']]) #here we have A, C, B label\n",
    "\n",
    "# as ohe_1 was trained on 2 labels, it can't process 3 labels now\n",
    "ohe_1.transform(Y) #Found unknown categories [np.str_('C')] in column 0 during transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56144be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can solve this by ignoring unknown labels\n",
    "\n",
    "ohe_1=OneHotEncoder(sparse_output=False,handle_unknown=\"ignore\")\n",
    "ohe_1.fit_transform(Y)\n",
    "\n",
    "#now it has assigned A = 1 0 0, B = 0 1 0, C =  0 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00ad4e",
   "metadata": {},
   "source": [
    "# With multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b398b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "enc=OneHotEncoder(sparse_output=False,categories=[[\"A\",\"B\",\"C\",\"D\"],[\"X\",\"Y\",\"Z\"]]) # assuming that we have 7 labels that's suppose to appear\n",
    "X=[[\"A\",\"X\"],[\"B\",\"Y\"],[\"C\",\"Z\"]] #and we have this as our labels\n",
    "enc.fit_transform(X)\n",
    "\n",
    "\"\"\"\n",
    "here \n",
    "A is\n",
    "1\n",
    "0\n",
    "0\n",
    "\n",
    "B is\n",
    "0 \n",
    "1\n",
    "0\n",
    "\n",
    "D is\n",
    "0\n",
    "0\n",
    "0\n",
    "\n",
    "because in X, we don't have D but we trained the encoder (enc) with A, B , C , D, X, Y & Z labels\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = [[\"D\",\"Z\"]]\n",
    "enc.fit_transform(Y)\n",
    "\n",
    "#As we trained the encoder that we will have A, B ,  C , D, X, Y, Z . So, it did set A=0, B=0, C=0 , D=1, X=0, Y=0, Z=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e54a5e",
   "metadata": {},
   "source": [
    "# Ordinal Encoding : Here Categories are converted to numerical values whereas \n",
    "\n",
    "Purpose: Designed for encoding feature variables (X) with ordinal categories (categories with an inherent order).\n",
    "\n",
    "Input: Works on 2D arrays (multiple columns).\n",
    "\n",
    "Output: Returns a 2D array where each category is replaced by an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e138253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "X=[[\"High\"],[\"Low\"],[\"Low\"],[\"Medium\"]]\n",
    "enc=OrdinalEncoder()\n",
    "enc.fit_transform(X)\n",
    "# here High as 0, Low as 1, Medium as 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d156d",
   "metadata": {},
   "source": [
    "# What if we want to customize , Low as 0, Medium as 1, High as 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed604f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_1=OrdinalEncoder(categories=[[\"Low\",\"Medium\",\"High\"]])\n",
    "enc_1.fit_transform(X)\n",
    "\n",
    "# High is 2, Low as 0, Medium as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22244d9",
   "metadata": {},
   "source": [
    "# Multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8492f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0.],\n",
       "       [0., 2.],\n",
       "       [0., 1.],\n",
       "       [1., 2.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=[[\"High\",\"A\"],[\"Low\",\"C\"],[\"Low\",\"B\"],[\"Medium\",\"C\"]]\n",
    "enc=OrdinalEncoder(categories=[[\"Low\",\"Medium\",\"High\"],[\"A\",\"B\",\"C\"]]) #training these labels , so that low is 0, Medium as 1, High 2\n",
    "# A as 0, B as 1, C as 2\n",
    "enc.fit_transform(X)\n",
    "\n",
    "# in output, 2 0 means High , A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2.]\n",
      " [1. 1.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = [[\"cat\", \"small\"], [\"dog\", \"medium\"], [\"cat\", \"large\"]]\n",
    "oe = OrdinalEncoder()\n",
    "X_encoded = oe.fit_transform(X)  # Output: array([[0., 1.], [1., 2.], [0., 0.]])\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba0520",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "Purpose: Primarily used for encoding target labels (i.e., the dependent variable y in supervised learning).\n",
    "\n",
    "Input: Works on 1D arrays (single column).\n",
    "\n",
    "Output: Returns a 1D array of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbde91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y=[\"A\",\"B\",\"B\",\"C\",\"D\"]\n",
    "enc=LabelEncoder()\n",
    "enc.fit_transform(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_0_Hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
