{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8e7f4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter\n",
       "0            NaN         10.38          122.80\n",
       "1          20.57         17.77          132.90\n",
       "2          19.69         21.25          130.00\n",
       "3          11.42         20.38           77.58\n",
       "4          20.29         14.34             NaN\n",
       "..           ...           ...             ...\n",
       "564        21.56         22.39          142.00\n",
       "565          NaN         28.25          131.20\n",
       "566        16.60         28.08          108.30\n",
       "567        20.60         29.33          140.10\n",
       "568         7.76           NaN           47.92\n",
       "\n",
       "[569 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"sample_dataset.csv\")\n",
    "X=df.iloc[:,0:3] # Selecting 3 column\n",
    "X # you can now see we have 569 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d019833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>15.22</td>\n",
       "      <td>30.62</td>\n",
       "      <td>103.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>20.92</td>\n",
       "      <td>25.09</td>\n",
       "      <td>143.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>385 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter\n",
       "1          20.57         17.77          132.90\n",
       "2          19.69         21.25          130.00\n",
       "3          11.42         20.38           77.58\n",
       "5          12.45         15.70           82.57\n",
       "7          13.71         20.83           90.20\n",
       "..           ...           ...             ...\n",
       "562        15.22         30.62          103.40\n",
       "563        20.92         25.09          143.00\n",
       "564        21.56         22.39          142.00\n",
       "566        16.60         28.08          108.30\n",
       "567        20.60         29.33          140.10\n",
       "\n",
       "[385 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,0:3].dropna() # Selecting 3 column, removing rows which are not a number\n",
    "X # you can now see that we have 385 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f21a2",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "0 - 1 scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0cfd101a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63004759, 0.27257355, 0.60432679],\n",
       "       [0.58687012, 0.3902604 , 0.58368915],\n",
       "       [0.18110004, 0.36083869, 0.21064617],\n",
       "       ...,\n",
       "       [0.67862225, 0.42881299, 0.66908625],\n",
       "       [0.43525833, 0.62123774, 0.42926274],\n",
       "       [0.63151955, 0.66351031, 0.65556504]], shape=(385, 3))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "X_scaled #scaled those 3 column values within 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b808f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor each column, find the maximum value\\n\\nIf X_scaled was min-max scaled (values normalized to [0,1] range):\\n\\nThe maximum value in each column will be exactly 1.0\\n\\nResult is a 1×3 array: [[max_of_col1, max_of_col2, max_of_col3]]'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For each column, find the maximum value\n",
    "\n",
    "If X_scaled was min-max scaled (values normalized to [0,1] range):\n",
    "\n",
    "The maximum value in each column will be exactly 1.0\n",
    "\n",
    "Result is a 1×3 array: [[max_of_col1, max_of_col2, max_of_col3]]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4e986241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_over_axes(np.max,X_scaled,0) # Max values → 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d62360d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor each column, find the minimum value\\n\\nWith min-max scaling, the minimum is always 0.0\\n\\nResult is [[min_of_col1, min_of_col2, min_of_col3]]\\n\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For each column, find the minimum value\n",
    "\n",
    "With min-max scaling, the minimum is always 0.0\n",
    "\n",
    "Result is [[min_of_col1, min_of_col2, min_of_col3]]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3bcab63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_over_axes(np.min,X_scaled,0) # Min values → 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29100b9",
   "metadata": {},
   "source": [
    "# Standardization\n",
    "\n",
    "Standardization (also called Z-score normalization) transforms data to have:\n",
    "\n",
    "- Mean = 0\n",
    "\n",
    "- Standard Deviation = 1\n",
    "\n",
    "- It rescales features so they follow a standard normal distribution (Gaussian distribution with μ=0, σ=1).\n",
    "\n",
    "For each feature (column), standardization is calculated as:\n",
    "\n",
    "\n",
    "\n",
    "X_standardized\n",
    "\n",
    "X − μ /σ\n",
    "\n",
    "​\n",
    "where, \n",
    "μ: Mean of the feature\n",
    "σ: Standard deviation of the feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a65620a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.87149535, -0.35527432,  1.7252216 ],\n",
       "       [ 1.61663638,  0.44774298,  1.6034021 ],\n",
       "       [-0.77845877,  0.24698866, -0.59859036],\n",
       "       ...,\n",
       "       [ 2.1582117 ,  0.71080038,  2.10748279],\n",
       "       [ 0.72173384,  2.02377982,  0.6918562 ],\n",
       "       [ 1.88018373,  2.31221994,  2.02767001]], shape=(385, 3))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "\n",
    "#  A new array X_scaled where each column has: Mean = 0; Std Dev = 1\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5323db9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.38226219e-17, -2.86062660e-16, -1.84556555e-17]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computes column means\n",
    "np.apply_over_axes(np.mean,X_scaled,0) #Computes the mean along axis 0 (columns) of X_scaled\n",
    "\n",
    "# Standardization forces each column to have: Mean = 0 ; Std Dev = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58a9b346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This NumPy operation computes the variance of each column in X_scaled\n",
    "np.apply_over_axes(np.var,X_scaled,0) #Since X_scaled is standardized: Variance of each column = 1\n",
    "#Variance=σ^2=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca499a5",
   "metadata": {},
   "source": [
    "# Robus Scaling\n",
    "\n",
    "Robust scaling is a data preprocessing technique that scales features using statistics that are resistant to outliers (unlike StandardScaler, which is sensitive to extreme values). It centers and scales data using the median and interquartile range (IQR) instead of the mean and standard deviation.\n",
    "\n",
    "Centering: Subtract the median (50th percentile) from each feature.\n",
    "\n",
    "X_centered=X−median(X)\n",
    "\n",
    "​Scaling: Divide by the IQR (75th percentile - 25th percentile).\n",
    "\n",
    "X_scaled = (X − median(X))/IQR(X)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cacd1620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.78484108, -0.18650089,  1.64689365],\n",
       "       [ 1.56968215,  0.43161634,  1.54510355],\n",
       "       [-0.45232274,  0.27708703, -0.29484029],\n",
       "       ...,\n",
       "       [ 2.02689487,  0.63410302,  1.96630397],\n",
       "       [ 0.81418093,  1.64476021,  0.78343278],\n",
       "       [ 1.79217604,  1.86678508,  1.8996139 ]], shape=(385, 3))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler=RobustScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "080c234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.apply_over_axes(np.median,X_scaled,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e2423",
   "metadata": {},
   "source": [
    "# Difference between RobustScaler and StandardScaler\n",
    "RobustScaler uses the median for centering and the interquartile range (IQR) for scaling, making it resistant to outliers. It’s ideal for skewed data or datasets with extreme values.\n",
    "\n",
    "StandardScaler uses the mean for centering and standard deviation for scaling, assuming a Gaussian-like distribution. It’s sensitive to outliers, as they distort the mean and std dev.\n",
    "\n",
    "Output: Both transform data to comparable scales, but RobustScaler preserves the structure of non-Gaussian data, while StandardScaler works best for normally distributed features.\n",
    "\n",
    "Use Cases:\n",
    "-----------\n",
    "\n",
    "RobustScaler: Outlier-prone data (e.g., finance, sensor readings).\n",
    "\n",
    "StandardScaler: Clean, Gaussian data (e.g., PCA, linear models).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e21da",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_0_Hero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
